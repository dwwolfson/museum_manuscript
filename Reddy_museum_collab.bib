
@software{appelhans2022,
  title = {Mapview: {{Interactive Viewing}} of {{Spatial Data}} in {{R}}},
  author = {Appelhans, Tim and Detsch, Florian and Reudenbach, Christoph and Woellauer, Stefan},
  date = {2022},
  url = {https://github.com/r-spatial/mapview},
  urldate = {2022-05-10},
  abstract = {Quickly and conveniently create interactive     visualisations of spatial data with or without background maps.     Attributes of displayed features are fully queryable via pop-up     windows. Additional functionality includes methods to visualise true-     and false-color raster images and bounding boxes.},
  version = {R package version 2.11.0.9000},
  file = {C\:\\Users\\David\\Zotero\\storage\\CWULKBQV\\mapview.html}
}

@article{bi2013,
  title = {Unlocking the Vault: Next-Generation Museum Population Genomics},
  shorttitle = {Unlocking the Vault},
  author = {Bi, Ke and Linderoth, Tyler and Vanderpool, Dan and Good, Jeffrey M. and Nielsen, Rasmus and Moritz, Craig},
  date = {2013},
  journaltitle = {Molecular Ecology},
  volume = {22},
  number = {24},
  pages = {6018--6032},
  issn = {1365-294X},
  doi = {10.1111/mec.12516},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/mec.12516},
  urldate = {2022-02-03},
  abstract = {Natural history museum collections provide unique resources for understanding how species respond to environmental change, including the abrupt, anthropogenic climate change of the past century. Ideally, researchers would conduct genome-scale screening of museum specimens to explore the evolutionary consequences of environmental changes, but to date such analyses have been severely limited by the numerous challenges of working with the highly degraded DNA typical of historic samples. Here, we circumvent these challenges by using custom, multiplexed, exon capture to enrich and sequence 11 000 exons ( 4 Mb) from early 20th-century museum skins. We used this approach to test for changes in genomic diversity accompanying a climate-related range retraction in the alpine chipmunks (Tamias alpinus) in the high Sierra Nevada area of California, USA. We developed robust bioinformatic pipelines that rigorously detect and filter out base misincorporations in DNA derived from skins, most of which likely resulted from postmortem damage. Furthermore, to accommodate genotyping uncertainties associated with low-medium coverage data, we applied a recently developed probabilistic method to call single-nucleotide polymorphisms and estimate allele frequencies and the joint site frequency spectrum. Our results show increased genetic subdivision following range retraction, but no change in overall genetic diversity at either nonsynonymous or synonymous sites. This case study showcases the advantages of integrating emerging genomic and statistical tools in museum collection-based population genomic applications. Such technical advances greatly enhance the value of museum collections, even where a pre-existing reference is lacking and points to a broad range of potential applications in evolutionary and conservation biology.},
  langid = {english},
  keywords = {DNA damage,exon capture,museum skins,natural history museum collections,nonmodel organisms,Tamias},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/mec.12516}
}

@software{boettiger2018,
  title = {{{RDF Storage}} and {{Retrieval}} with Rdflib},
  author = {Boettiger, Carl},
  date = {2018},
  url = {https://doi.org/10.5281/zenodo.1098478},
  urldate = {2022-04-01},
  file = {C\:\\Users\\David\\Zotero\\storage\\X4BUI8TX\\mindswap.html}
}

@article{booth2021,
  title = {Museum Open Data Ecosystems: A Comparative Study},
  shorttitle = {Museum Open Data Ecosystems},
  author = {Booth, Peter and Navarrete, Trilce and Ogundipe, Anne},
  date = {2021-01-01},
  journaltitle = {Journal of Documentation},
  volume = {ahead-of-print},
  issn = {0022-0418},
  doi = {10.1108/JD-05-2021-0102},
  url = {https://doi.org/10.1108/JD-05-2021-0102},
  urldate = {2022-04-14},
  abstract = {Purpose This study aims to investigate how, in forming their policy towards open data (OD), art museums interact with the OD ecosystems they are part of, comprising internal and external components such as cultural policy, legal frameworks, user groups and economic conditions and incentives. Design/methodology/approach The authors structure their research as a multiple case study based on three OD ecosystems, each defined by a mid-sized European art museum at its centre. Qualitative analysis of the case studies proceeds from interviews with museum management staff and policy-related agencies in three European countries, in addition to document analysis. Findings The results of this study suggest that museums are sensitive towards their environments and respond to their ecosystem based on what is communicated within their networks. However, museums are not effective in communicating with their users, limiting the informational interdependence necessary for well-functioning OD ecosystems. EU policy appears to be a driving force along with national financial incentives, though institutional conditions are limiting progress. Advancing the field relies instead on an epistemological shift to understand the museum as part of a larger information network. Originality/value As the first comparative case study of art museum OD ecosystems that the authors are aware of, the study provides a qualitative analysis of the complex dynamics impacting OD policy within the mid-sized art museum. The authors identify specific dynamics that are thus far restricting further development of the OD ecosystem of the mid-sized European art museum.},
  issue = {ahead-of-print},
  keywords = {Cultural policy,Ecosystems,Museums,Networks,Open data,Reuse,Users}
}

@article{borsch2020,
  title = {A Complete Digitization of {{German}} Herbaria Is Possible, Sensible and Should Be Started Now},
  author = {Borsch, Thomas and Stevens, Albert-Dieter and Häffner, Eva and Güntsch, Anton and Berendsohn, Walter G. and Appelhans, Marc and Barilaro, Christina and Beszteri, Bánk and Blattner, Frank and Bossdorf, Oliver and Dalitz, Helmut and Dressler, Stefan and Duque-Thüs, Rhinaixa and Esser, Hans-Joachim and Franzke, Andreas and Goetze, Dethardt and Grein, Michaela and Grünert, Uta and Hellwig, Frank and Hentschel, Jörn and Hörandl, Elvira and Janßen, Thomas and Jürgens, Norbert and Kadereit, Gudrun and Karisch, Timm and Koch, Marcus and Müller, Frank and Müller, Jochen and Ober, Dietrich and Porembski, Stefan and Poschlod, Peter and Printzen, Christian and Röser, Martin and Sack, Peter and Schlüter, Philipp and Schmidt, Marco and Schnittler, Martin and Scholler, Markus and Schultz, Matthias and Seeber, Elke and Simmel, Josef and Stiller, Michael and Thiv, Mike and Thüs, Holger and Tkach, Natalia and Triebel, Dagmar and Warnke, Ursula and Weibulat, Tanja and Wesche, Karsten and Yurkov, Andrey and Zizka, Georg},
  date = {2020-02-03},
  journaltitle = {Research Ideas and Outcomes},
  shortjournal = {RIO},
  volume = {6},
  pages = {e50675},
  issn = {2367-7163},
  doi = {10.3897/rio.6.e50675},
  url = {https://riojournal.com/article/50675/},
  urldate = {2022-04-02},
  abstract = {Plants, fungi and algae are important components of global biodiversity and are fundamental to all ecosystems. They are the basis for human well-being, providing food, materials and medicines. Specimens of all three groups of organisms are accommodated in herbaria, where they are commonly referred to as botanical specimens.},
  langid = {english},
  file = {C\:\\Users\\David\\Zotero\\storage\\IREK6AHP\\Borsch et al. - 2020 - A complete digitization of German herbaria is poss.pdf}
}

@article{brlik2022,
  title = {The Reuse of Avian Samples: Opportunities, Pitfalls, and a Solution},
  shorttitle = {The Reuse of Avian Samples},
  author = {Brlík, Vojtěch and Pipek, Pavel and Brandis, Kate and Chernetsov, Nikita and Costa, Fábio J. V. and Herrera M., L. Gerardo and Kiat, Yosef and Lanctot, Richard B. and Marra, Peter P. and Norris, D. Ryan and Nwaogu, Chima J. and Quillfeldt, Petra and Saalfeld, Sarah T. and Stricker, Craig A. and Thomson, Robert L. and Zhao, Tianhao and Procházka, Petr},
  date = {2022},
  journaltitle = {Ibis},
  volume = {164},
  number = {1},
  pages = {343--349},
  issn = {1474-919X},
  doi = {10.1111/ibi.12997},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/ibi.12997},
  urldate = {2022-03-25},
  abstract = {Tissue samples are frequently collected to study various aspects of avian biology, but in many cases these samples are not used in their entirety and are stored by the collector. The already collected samples provide a largely overlooked opportunity because they can be used by different researchers in different biological fields. Broad reuse of samples could result in multispecies or large-scale studies, interdisciplinary collaborations, and the generation of new ideas, thereby increasing the quality and impact of research. Sample reuse could also reduce the number of new samples needed for a study, which is especially pertinent to endangered species where sample collection is necessarily limited. Importantly, reusing samples may be mutually beneficial for both the researchers providing samples and those reusing them. Here, we identify the benefits of sample reuse, describe currently available sources of already collected samples and their limitations, and highlight the wide range of potential applications in a single research field – avian isotopic ecology. To facilitate the reuse of avian samples worldwide and across research fields, we introduce the AviSample Network metadata repository. The main aims of this metadata repository are to collate and provide access to descriptions of available avian tissue samples. We contend that the creation of the AviSample Network metadata repository will provide the opportunity for new collaborations and studies. Moreover, we believe that this will help create research connections between ornithologists across the globe and encourage sample reuse in other fields.},
  langid = {english},
  keywords = {birds,database,metadata,sample,tissue,transparency},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/ibi.12997},
  file = {C\:\\Users\\David\\Zotero\\storage\\MN2AZPQI\\ibi.html}
}

@misc{chamberlain2017,
  title = {R {{Python}}, and {{Ruby}} Clients for {{GBIF}} Species Occurrence Data},
  author = {Chamberlain, Scott A. and Boettiger, Carl},
  date = {2017-09-29},
  publisher = {{PeerJ Inc.}},
  issn = {2167-9843},
  doi = {10.7287/peerj.preprints.3304v1},
  url = {https://peerj.com/preprints/3304},
  urldate = {2022-05-11},
  abstract = {Background. The number of individuals of each species in a given location forms the basis for many sub-fields of ecology and evolution. Data on individuals, including which species, and where they're found can be used for a large number of research questions. Global Biodiversity Information Facility (hereafter, GBIF) is the largest of these. Programmatic clients for GBIF would make research dealing with GBIF data much easier and more reproducible. Methods. We have developed clients to access GBIF data for each of the R, Python, and Ruby programming languages: rgbif, pygbif, gbifrb. Results. For all clients we describe their design and utility, and demonstrate some use cases. Discussion. Programmatic access to GBIF will facilitate more open and reproducible science - the three GBIF clients described herein are a significant contribution towards this goal.},
  langid = {english},
  file = {C\:\\Users\\David\\Zotero\\storage\\PUH7BTQ6\\3304.html}
}

@article{colella2021,
  title = {The {{Open-Specimen Movement}}},
  author = {Colella, Jocelyn P and Stephens, Ryan B and Campbell, Mariel L and Kohli, Brooks A and Parsons, Danielle J and Mclean, Bryan S},
  date = {2021-04-12},
  journaltitle = {BioScience},
  shortjournal = {BioScience},
  volume = {71},
  number = {4},
  pages = {405--414},
  issn = {0006-3568},
  doi = {10.1093/biosci/biaa146},
  url = {https://doi.org/10.1093/biosci/biaa146},
  urldate = {2022-03-25},
  abstract = {The open-science movement seeks to increase transparency, reproducibility, and access to scientific data. As primary data, preserved biological specimens represent records of global biodiversity critical to research, conservation, national security, and public health. However, a recent decrease in specimen preservation in public biorepositories is a major barrier to open biological science. As such, there is an urgent need for a cultural shift in the life sciences that normalizes specimen deposition in museum collections. Museums embody an open-science ethos and provide long-term research infrastructure through curation, data management and security, and community-wide access to samples and data, thereby ensuring scientific reproducibility and extension. We propose that a paradigm shift from specimen ownership to specimen stewardship can be achieved through increased open-data requirements among scientific journals and institutional requirements for specimen deposition by funding and permitting agencies, and through explicit integration of specimens into existing data management plan guidelines and annual reporting.},
  file = {C\:\\Users\\David\\Zotero\\storage\\M4U9I8EY\\6030117.html}
}

@article{costello2014,
  title = {Best Practice for Biodiversity Data Management and Publication},
  author = {Costello, Mark J. and Wieczorek, John},
  date = {2014-05-01},
  journaltitle = {Biological Conservation},
  shortjournal = {Biological Conservation},
  volume = {173},
  pages = {68--73},
  issn = {0006-3207},
  doi = {10.1016/j.biocon.2013.10.018},
  url = {https://www.sciencedirect.com/science/article/pii/S000632071300373X},
  urldate = {2022-04-14},
  abstract = {There is increasing pressure from the scientific community, including funding agencies, journals and peers, for authors to publish the biodiversity data used in published articles and other scientific literature. This enables reproducibility of research and creates new opportunities for integrating data between research projects and analysing data in additional ways. The long-term availability of data is especially important in conservation science because field data can be costly to collect. In addition, historic data, especially on threatened species and their associated biota, become more valuable over time. This paper summarises current standards and best practices for the management and publication of biodiversity data. It includes recommendations for citing sources of species determination and standards for formatting species distribution data. Whenever possible, data should be published for inclusion in data access platforms that integrate datasets (e.g. GBIF, GenBank) and so enable new analyses and broader impact. Data centres (e.g. PANGAEA) provide added value in quality checks on data. A minimum standard recommended is that data should be permanently archived in an online, open-access repository with sufficient metadata for potential users to understand how and why they were collected.},
  langid = {english},
  keywords = {Biodiversity informatics,Conservation,Data standards,Global Biodiversity Information Facility,Methods,Ocean Biogeographic Information System,Species 2000,World Register of Marine Species},
  file = {C\:\\Users\\David\\Zotero\\storage\\37CT2P6D\\S000632071300373X.html}
}

@article{dallas2016,
  title = {{{helminthR}}: An {{R}} Interface to the {{London Natural History Museum}}'s {{Host}}–{{Parasite Database}}},
  shorttitle = {{{helminthR}}},
  author = {Dallas, Tad},
  date = {2016},
  journaltitle = {Ecography},
  volume = {39},
  number = {4},
  pages = {391--393},
  issn = {1600-0587},
  doi = {10.1111/ecog.02131},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/ecog.02131},
  urldate = {2022-04-01},
  abstract = {The understanding of the diversity and distribution of helminth parasites is currently constrained by the limited number of host–parasite interaction databases, and the difficulty in accessing existing data. The London Natural History Museum's Host–Parasite Database represents one such underutilized database, containing over a quarter million helminth parasite occurrence records, accessible through a web interface. To enable users to programmatically search and manipulate data from this database, I developed an R package called helminthR. Here, I introduce the core functions of the package, and detail how helminthR can be used to obtain host–parasite interaction records, citations for interactions, and host taxonomic data.},
  langid = {english},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/ecog.02131},
  file = {C\:\\Users\\David\\Zotero\\storage\\PK2ASRQ8\\ecog.html}
}

@article{davidson2021,
  title = {Mobilizing {{Animal Movement Data}}: {{API}} Use and the {{Movebank}} Platform},
  shorttitle = {Mobilizing {{Animal Movement Data}}},
  author = {Davidson, Sarah and Bohrer, Gil and Kölzsch, Andrea and Vinciguerra, Candace and Kays, Roland},
  date = {2021-09-13},
  journaltitle = {Biodiversity Information Science and Standards},
  shortjournal = {BISS},
  volume = {5},
  pages = {e74312},
  issn = {2535-0897},
  doi = {10.3897/biss.5.74312},
  url = {https://biss.pensoft.net/article/74312/},
  urldate = {2022-04-14},
  abstract = {Movebank, a global platform for animal tracking and other animal-borne sensor data, is used by over 3,000 researchers globally to harmonize, archive and share nearly 3 billion animal occurrence records and more than 3 billion other animal-borne sensor measurements that document the movements and behavior of over 1,000 species. Movebank’s publicly described data model (Kranstauber et al. 2011), vocabulary and application programming interfaces (APIs) provide services for users to automate data import and retrieval. Near-live data feeds are maintained in cooperation with over 20 manufacturers of animal-borne sensors, who provide data in agreed-upon formats for accurate data import. Data acquisition by API complies with public or controlled-access sharing settings, defined within the database by data owners. The Environmental Data Automated Track Annotation System (EnvDATA, Dodge et al. 2013) allows users to link animal tracking data with hundreds of environmental parameters from remote sensing and weather reanalysis products through the Movebank website, and offers an API for advanced users to automate the submission of annotation requests. Movebank's mobile apps, the Animal Tracker and Animal Tagger, use APIs to support reporting and monitoring while in the field, as well as communication with citizen scientists. The recently-launched MoveApps platform connects with Movebank data using an API to allow users to build, execute and share repeatable workflows for data exploration and analysis through a user-friendly interface. A new API, currently under development, will allow calls to retrieve data from Movebank reduced according to criteria defined by "reduction profiles", which can greatly reduce the volume of data transferred for many use cases.             In addition to making this core set of Movebank services possible, Movebank's APIs enable the development of external applications, including the widely used R programming packages 'move' (Kranstauber et al. 2012) and 'ctmm' (Calabrese et al. 2016), and user-specific workflows to efficiently execute collaborative analyses and automate tasks such as syncing with local organizational and governmental websites and archives. The APIs also support large-scale data acquisition, including for projects under development to visualize, map and analyze bird migrations led by the British Trust for Ornithology, the coordinating organisation for European bird ringing (banding) schemes (EURING), Georgetown University, National Audubon Society, Smithsonian Institution and United Nations Convention on Migratory Species.             Our API development is constrained by a lack of standardization in data reporting across animal-borne sensors and a need to ensure adequate communication with data users (e.g., how to properly interpret data; expectations for use and attribution) and data owners (e.g., who is using publicly-available data and how) when allowing automated data access. As interest in data linking, harvesting, mirroring and integration grows, we recognize needs to coordinate API development across animal tracking and biodiversity databases, and to develop a shared system for unique organism identifiers. Such a system would allow linking of information about individual animals within and across repositories and publications in order to recognize data for the same individuals across platforms, retain provenance and attribution information, and ensure beneficial and biologically meaningful data use.},
  langid = {english},
  file = {C\:\\Users\\David\\Zotero\\storage\\BBKZDA3S\\Davidson et al. - 2021 - Mobilizing Animal Movement Data API use and the M.pdf}
}

@article{droege2014,
  title = {The {{Global Genome Biodiversity Network}} ({{GGBN}}) {{Data Portal}}},
  author = {Droege, Gabriele and Barker, Katharine and Astrin, Jonas J. and Bartels, Paul and Butler, Carol and Cantrill, David and Coddington, Jonathan and Forest, Félix and Gemeinholzer, Birgit and Hobern, Donald and Mackenzie-Dodds, Jacqueline and Ó Tuama, Éamonn and Petersen, Gitte and Sanjur, Oris and Schindel, David and Seberg, Ole},
  date = {2014-01-01},
  journaltitle = {Nucleic Acids Research},
  shortjournal = {Nucleic Acids Res},
  volume = {42},
  eprint = {24137012},
  eprinttype = {pmid},
  pages = {D607-D612},
  issn = {0305-1048},
  doi = {10.1093/nar/gkt928},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3965106/},
  urldate = {2022-04-01},
  abstract = {The Global Genome Biodiversity Network (GGBN) was formed in 2011 with the principal aim of making high-quality well-documented and vouchered collections that store DNA or tissue samples of biodiversity, discoverable for research through a networked community of biodiversity repositories. This is achieved through the GGBN Data Portal (http://data.ggbn.org), which links globally distributed databases and bridges the gap between biodiversity repositories, sequence databases and research results. Advances in DNA extraction techniques combined with next-generation sequencing technologies provide new tools for genome sequencing. Many ambitious genome sequencing projects with the potential to revolutionize biodiversity research consider access to adequate samples to be a major bottleneck in their workflow. This is linked not only to accelerating biodiversity loss and demands to improve conservation efforts but also to a lack of standardized methods for providing access to genomic samples. Biodiversity biobank-holding institutions urgently need to set a standard of collaboration towards excellence in collections stewardship, information access and sharing and responsible and ethical use of such collections. GGBN meets these needs by enabling and supporting accessibility and the efficient coordinated expansion of biodiversity biobanks worldwide.},
  issue = {Database issue},
  pmcid = {PMC3965106}
}

@article{freedman2018,
  title = {Destructive Sampling Natural Science Collections: An Overview for Museum Professionals and Researchers},
  shorttitle = {Destructive Sampling Natural Science Collections},
  author = {Freedman, J. and van Dorp, L. B. and Brace, S.},
  options = {useprefix=true},
  date = {2018},
  journaltitle = {Journal of Natural Science Collections},
  volume = {5},
  pages = {21--34},
  url = {https://www.natsca.org/article/2440},
  urldate = {2022-02-03},
  abstract = {There are many reasons why museum collections may be used for destructive sampling, from DNA and isotope analysis to radiocarbon dating. The process is invasive and destroys a part, or all, of the specimen. This can result in reluctance by museum staff to allow specimens to be used in particular types of scientific research. We will present some of the motivations on both sides, but argue that the benefits of destructive sampling can outweigh the risks. Many analytical methods have improved dramatically in the last 30 years, requiring smaller sample sizes. With a focus on destructive sampling for genetic analysis, we will also present some examples from the literature where DNA from museum and archaeological specimens has greatly aided the reconstruction of a species' evolutionary history as well as enriching our understanding of the object sampled. In addition, we highlight the need for museum staff to understand exactly what researchers are asking for, and for researchers in turn to understand museum procedures. We include an example of a Destructive Sampling Policy and a Destructive Sampling Request Form, for institutions to adapt for their own use.},
  langid = {english},
  file = {C\:\\Users\\David\\Zotero\\storage\\ZCX46ZPR\\10048229.html}
}

@article{gadelhajr2021,
  title = {A Survey of Biodiversity Informatics: {{Concepts}}, Practices, and Challenges},
  shorttitle = {A Survey of Biodiversity Informatics},
  author = {Gadelha Jr, Luiz M. R. and de Siracusa, Pedro C. and Dalcin, Eduardo Couto and da Silva, Luís Alexandre Estevão and Augusto, Douglas A. and Krempser, Eduardo and Affe, Helen Michelle and Costa, Raquel Lopes and Mondelli, Maria Luiza and Meirelles, Pedro Milet and Thompson, Fabiano and Chame, Marcia and Ziviani, Artur and de Siqueira, Marinez Ferreira},
  options = {useprefix=true},
  date = {2021},
  journaltitle = {WIREs Data Mining and Knowledge Discovery},
  volume = {11},
  number = {1},
  pages = {e1394},
  issn = {1942-4795},
  doi = {10.1002/widm.1394},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/widm.1394},
  urldate = {2022-05-11},
  abstract = {The unprecedented size of the human population, along with its associated economic activities, has an ever-increasing impact on global environments. Across the world, countries are concerned about the growing resource consumption and the capacity of ecosystems to provide resources. To effectively conserve biodiversity, it is essential to make indicators and knowledge openly available to decision-makers in ways that they can effectively use them. The development and deployment of tools and techniques to generate these indicators require having access to trustworthy data from biological collections, field surveys and automated sensors, molecular data, and historic academic literature. The transformation of these raw data into synthesized information that is fit for use requires going through many refinement steps. The methodologies and techniques applied to manage and analyze these data constitute an area usually called biodiversity informatics. Biodiversity data follow a life cycle consisting of planning, collection, certification, description, preservation, discovery, integration, and analysis. Researchers, whether producers or consumers of biodiversity data, will likely perform activities related to at least one of these steps. This article explores each stage of the life cycle of biodiversity data, discussing its methodologies, tools, and challenges. This article is categorized under: Algorithmic Development {$>$} Biological Data Mining},
  langid = {english},
  keywords = {biodiversity informatics,computational modeling,scientific data management,scientific workflows},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/widm.1394},
  file = {C\:\\Users\\David\\Zotero\\storage\\V2M8ALMI\\widm.html}
}

@article{glockler2020,
  title = {{{DINA}}—{{Development}} of Open Source and Open Services for Natural History Collections \&amp; Research},
  author = {Glöckler, Falko and Macklin, James and Shorthouse, David and Bölling, Christian and Bilkhu, Satpal and Gendreau, Christian},
  date = {2020-10-06},
  journaltitle = {Biodiversity Information Science and Standards},
  shortjournal = {BISS},
  volume = {4},
  pages = {e59070},
  issn = {2535-0897},
  doi = {10.3897/biss.4.59070},
  url = {https://biss.pensoft.net/article/59070/},
  urldate = {2022-04-02},
  abstract = {The DINA Consortium (DINA = “DIgital information system for NAtural history data”, https:// dina-project.net) is a framework for like-minded practitioners of natural history collections to collaborate on the development of distributed, open source software that empowers and sustains collections management. Target collections include zoology, botany, mycology, geology, paleontology, and living collections. The DINA software will also permit the compilation of biodiversity inventories and will robustly support both observation and molecular data.},
  langid = {english},
  file = {C\:\\Users\\David\\Zotero\\storage\\23HI626R\\Glöckler et al. - 2020 - DINA—Development of open source and open services .pdf}
}

@article{graham2004,
  title = {New Developments in Museum-Based Informatics and Applications in Biodiversity Analysis},
  author = {Graham, Catherine H. and Ferrier, Simon and Huettman, Falk and Moritz, Craig and Peterson, A. Townsend},
  date = {2004-09-01},
  journaltitle = {Trends in Ecology \& Evolution},
  shortjournal = {Trends in Ecology \& Evolution},
  volume = {19},
  number = {9},
  pages = {497--503},
  issn = {0169-5347},
  doi = {10.1016/j.tree.2004.07.006},
  url = {https://www.sciencedirect.com/science/article/pii/S0169534704002034},
  urldate = {2022-05-10},
  abstract = {Information from natural history collections (NHCs) about the diversity, taxonomy and historical distributions of species worldwide is becoming increasingly available over the Internet. In light of this relatively new and rapidly increasing resource, we critically review its utility and limitations for addressing a diverse array of applications. When integrated with spatial environmental data, NHC data can be used to study a broad range of topics, from aspects of ecological and evolutionary theory, to applications in conservation, agriculture and human health. There are challenges inherent to using NHC data, such as taxonomic inaccuracies and biases in the spatial coverage of data, which require consideration. Promising research frontiers include the integration of NHC data with information from comparative genomics and phylogenetics, and stronger connections between the environmental analysis of NHC data and experimental and field-based tests of hypotheses.},
  langid = {english},
  file = {C\:\\Users\\David\\Zotero\\storage\\K49SLAH7\\S0169534704002034.html}
}

@article{guntsch2009,
  title = {{{EFFECTIVELY SEARCHING SPECIMEN AND OBSERVATION DATA WITH TOQE}}, {{THE THESAURUS OPTIMIZED QUERY EXPANDER}}},
  author = {Güntsch, Anton and Hoffmann, Niels and Kelbert, Patricia and Berendsohn, Walter G.},
  date = {2009-09-05},
  journaltitle = {Biodiversity Informatics},
  shortjournal = {Biodiv. Inf.},
  volume = {6},
  number = {1},
  issn = {15469735},
  doi = {10.17161/bi.v6i1.1631},
  url = {https://journals.ku.edu/jbi/article/view/1631},
  urldate = {2022-03-25},
  abstract = {Today’s specimen and observation data portals lack a flexible search mechanism, able to link up thesaurus-enabled data sources such as taxonomic checklist databases and expand user queries to related terms, significantly enhancing result sets. The TOQE system (Thesaurus Optimized Query Expander) is a REST-like XML web-service implemented in Python and designed for this purpose. Acting as an interface between portals and thesauri, TOQE allows the implementation of specialized portal systems with a set of thesauri supporting its specific focus. It is both easy to use for portal programmers and easy to configure for thesaurus database holders who want to expose their system as a service for query expansions. Currently, TOQE is used in four specimen and observation data portals. The documentation is available from http://search.biocase.org/toqe/.},
  langid = {english},
  file = {C\:\\Users\\David\\Zotero\\storage\\D6Y2UAW3\\Güntsch et al. - 2009 - EFFECTIVELY SEARCHING SPECIMEN AND OBSERVATION DAT.pdf}
}

@article{guralnick2007,
  title = {Towards a Collaborative, Global Infrastructure for Biodiversity Assessment},
  author = {Guralnick, Robert P. and Hill, Andrew W. and Lane, Meredith},
  date = {2007-08},
  journaltitle = {Ecology Letters},
  shortjournal = {Ecol Letters},
  volume = {10},
  number = {8},
  pages = {663--672},
  issn = {1461-023X, 1461-0248},
  doi = {10.1111/j.1461-0248.2007.01063.x},
  url = {https://onlinelibrary.wiley.com/doi/10.1111/j.1461-0248.2007.01063.x},
  urldate = {2022-05-10},
  abstract = {Biodiversity data are rapidly becoming available over the Internet in common formats that promote sharing and exchange. Currently, these data are somewhat problematic, primarily with regard to geographic and taxonomic accuracy, for use in ecological research, natural resources management and conservation decision-making. However, web-based georeferencing tools that utilize best practices and gazetteer databases can be employed to improve geographic data. Taxonomic data quality can be improved through web-enabled valid taxon names databases and services, as well as more efficient mechanisms to return systematic research results and taxonomic misidentification rates back to the biodiversity community. Both of these are under construction. A separate but related challenge will be developing web-based visualization and analysis tools for tracking biodiversity change. Our aim was to discuss how such tools, combined with data of enhanced quality, will help transform today’s portals to raw biodiversity data into nexuses of collaborative creation and sharing of biodiversity knowledge.},
  langid = {english},
  file = {C\:\\Users\\David\\Zotero\\storage\\LFGMB5ED\\Guralnick et al. - 2007 - Towards a collaborative, global infrastructure for.pdf}
}

@article{guralnick2009,
  title = {Biodiversity Informatics: Automated Approaches for Documenting Global Biodiversity Patterns and Processes},
  shorttitle = {Biodiversity Informatics},
  author = {Guralnick, Robert and Hill, Andrew},
  date = {2009-02-15},
  journaltitle = {Bioinformatics},
  shortjournal = {Bioinformatics},
  volume = {25},
  number = {4},
  pages = {421--428},
  issn = {1367-4803},
  doi = {10.1093/bioinformatics/btn659},
  url = {https://doi.org/10.1093/bioinformatics/btn659},
  urldate = {2022-05-10},
  abstract = {Motivation: Data about biodiversity have been scattered in different formats in natural history collections, survey reports and the literature. A central challenge for the biodiversity informatics community is to provide the means to share and rapidly synthesize these data and the knowledge they provide us to build an easily accessible, unified global map of biodiversity. Such a map would provide raw and summary data and information on biodiversity and its change across the world at multiple scales.Results: We discuss a series of steps required to create a unified global map of biodiversity. These steps include: building biodiversity repositories; creating scalable species distribution maps; creating flexible, user-programmable pipelines which enable biodiversity assessment; and integrating phylogenetic approaches into biodiversity assessment. We show two case studies that combine phyloinformatic and biodiversity informatic approaches to document large scale biodiversity patterns. The first case study uses data available from the Barcode of Life initiative in order to make species conservation assessment of North American birds taking into account evolutionary uniqueness. The second case study uses full genomes of influenza A available from Genbank to provide an auto-updating documentation of the evolution and geographic spread of these viruses.Availability: Both the website for tracking evolution and spread of influenza A and the website for applying phyloinformatics analysis to Barcode of Life data are available as outcomes of case studies (http://biodiversity.colorado.edu).Contact:robert.guralnick@colorado.edu},
  file = {C\:\\Users\\David\\Zotero\\storage\\MFC5TZJJ\\250049.html}
}

@article{hedrick2020,
  title = {Digitization and the {{Future}} of {{Natural History Collections}}},
  author = {Hedrick, Brandon P and Heberling, J Mason and Meineke, Emily K and Turner, Kathryn G and Grassa, Christopher J and Park, Daniel S and Kennedy, Jonathan and Clarke, Julia A and Cook, Joseph A and Blackburn, David C and Edwards, Scott V and Davis, Charles C},
  date = {2020-03-01},
  journaltitle = {BioScience},
  shortjournal = {BioScience},
  volume = {70},
  number = {3},
  pages = {243--251},
  issn = {0006-3568},
  doi = {10.1093/biosci/biz163},
  url = {https://doi.org/10.1093/biosci/biz163},
  urldate = {2022-03-25},
  abstract = {Natural history collections (NHCs) are the foundation of historical baselines for assessing anthropogenic impacts on biodiversity. Along these lines, the online mobilization of specimens via digitization—the conversion of specimen data into accessible digital content—has greatly expanded the use of NHC collections across a diversity of disciplines. We broaden the current vision of digitization (Digitization 1.0)—whereby specimens are digitized within NHCs—to include new approaches that rely on digitized products rather than the physical specimen (Digitization 2.0). Digitization 2.0 builds on the data, workflows, and infrastructure produced by Digitization 1.0 to create digital-only workflows that facilitate digitization, curation, and data links, thus returning value to physical specimens by creating new layers of annotation, empowering a global community, and developing automated approaches to advance biodiversity discovery and conservation. These efforts will transform large-scale biodiversity assessments to address fundamental questions including those pertaining to critical issues of global change.},
  file = {C\:\\Users\\David\\Zotero\\storage\\DXZU57CZ\\5729294.html}
}

@article{janicki2016,
  title = {Visualizing and Interacting with Large-Volume Biodiversity Data Using Client–Server Web-Mapping Applications: {{The}} Design and Implementation of Antmaps.Org},
  shorttitle = {Visualizing and Interacting with Large-Volume Biodiversity Data Using Client–Server Web-Mapping Applications},
  author = {Janicki, Julia and Narula, Nitish and Ziegler, Matt and Guénard, Benoit and Economo, Evan P.},
  date = {2016-03-01},
  journaltitle = {Ecological Informatics},
  shortjournal = {Ecological Informatics},
  volume = {32},
  pages = {185--193},
  issn = {1574-9541},
  doi = {10.1016/j.ecoinf.2016.02.006},
  url = {https://www.sciencedirect.com/science/article/pii/S1574954116300097},
  urldate = {2022-05-10},
  abstract = {The rise of informatics has presented new opportunities for analyzing, visualizing, and interacting with data across the sciences, and biodiversity science is no exception. Recently, comprehensive datasets on the geographic distributions of species have been assembled that represent a thorough accounting of a given taxonomic group of species (e.g. birds, mammals, etc.), and which form critical tools for both basic biology and conservation. However, these databases present several challenges for visualization, interaction, and participation for users across a broad range of scientists and the public. In support of the development of a new comprehensive ant biodiversity database containing over 1.7 million records, we developed a new client–server web-mapping application, antmaps.org, to visualize and interact with the geographic distributions of all 15,050 ant species and aggregate patterns of their diversity and biogeography. Our application development approach was based on user-centered design principles of usability engineering, human-computer interaction, and cartography. The resulting application is highly focused on providing efficient and intuitive access to geographic biodiversity data using a client–server interaction that allows users to query and retrieve data on the fly. This is achieved with a backend solution to efficiently work with large volumes of geospatial data. The usability and utility of the final version of the application was measured based on effectiveness, efficiency and user satisfaction, and assessed using questionnaires, usability lab studies and surveys. While the development of antmaps.org was motivated by a particular ant biodiversity dataset, the basic framework, design, and functionality are not specific to ants and could be used to interact with biodiversity data of any taxonomic group.},
  langid = {english},
  keywords = {Ants,Biodiversity informatics,Cartographic design,Client–server,D3js,Database,User-centered design,Web-mapping},
  file = {C\:\\Users\\David\\Zotero\\storage\\Y7A7PZME\\S1574954116300097.html}
}

@article{kays2022,
  title = {The {{Movebank}} System for Studying Global Animal Movement and Demography},
  author = {Kays, Roland and Davidson, Sarah C. and Berger, Matthias and Bohrer, Gil and Fiedler, Wolfgang and Flack, Andrea and Hirt, Julian and Hahn, Clemens and Gauggel, Dominik and Russell, Benedict and Kölzsch, Andrea and Lohr, Ashley and Partecke, Jesko and Quetting, Michael and Safi, Kamran and Scharf, Anne and Schneider, Gabriel and Lang, Ilona and Schaeuffelhut, Friedrich and Landwehr, Matthias and Storhas, Martin and van Schalkwyk, Louis and Vinciguerra, Candace and Weinzierl, Rolf and Wikelski, Martin},
  options = {useprefix=true},
  date = {2022},
  journaltitle = {Methods in Ecology and Evolution},
  volume = {13},
  number = {2},
  pages = {419--431},
  issn = {2041-210X},
  doi = {10.1111/2041-210X.13767},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.13767},
  urldate = {2022-04-14},
  abstract = {Quantifying movement and demographic events of free-ranging animals is fundamental to studying their ecology, evolution and conservation. Technological advances have led to an explosion in sensor-based methods for remotely observing these phenomena. This transition to big data creates new challenges for data management, analysis and collaboration. We present the Movebank ecosystem of tools used by thousands of researchers to collect, manage, share, visualize, analyse and archive their animal tracking and other animal-borne sensor data. Users add sensor data through file uploads or live data streams and further organize and complete quality control within the Movebank system. All data are harmonized to a data model and vocabulary. The public can discover, view and download data for which they have been given access to through the website, the Animal Tracker mobile app or by API. Advanced analysis tools are available through the EnvDATA System, the MoveApps platform and a variety of user-developed applications. Data owners can share studies with select users or the public, with options for embargos, licenses and formal archiving in a data repository. Movebank is used by over 3,100 data owners globally, who manage over 6 billion animal location and sensor measurements across more than 6,500 studies, with thousands of active tags sending over 3 million new data records daily. These data underlie {$>$}700 published papers and reports. We present a case study demonstrating the use of Movebank to assess life-history events and demography, and engage with citizen scientists to identify mortalities and causes of death for a migratory bird. A growing number of researchers, government agencies and conservation organizations use Movebank to manage research and conservation projects and to meet legislative requirements. The combination of historic and new data with collaboration tools enables broad comparative analyses and data acquisition and mapping efforts. Movebank offers an integrated system for real-time monitoring of animals at a global scale and represents a digital museum of animal movement and behaviour. Resources and coordination across countries and organizations are needed to ensure that these data, including those that cannot be made public, remain accessible to future generations.},
  langid = {english},
  keywords = {animal behaviour,animal tracking,bio-logging,cyberinfrastructure,FAIR data,GPS,live data,movement},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/2041-210X.13767},
  file = {C\:\\Users\\David\\Zotero\\storage\\XNJWEIKH\\2041-210X.html}
}

@article{kranstauber2011,
  title = {The {{Movebank}} Data Model for Animal Tracking},
  author = {Kranstauber, B. and Cameron, A. and Weinzerl, R. and Fountain, T. and Tilak, S. and Wikelski, M. and Kays, R.},
  date = {2011-06-01},
  journaltitle = {Environmental Modelling \& Software},
  shortjournal = {Environmental Modelling \& Software},
  volume = {26},
  number = {6},
  pages = {834--835},
  issn = {1364-8152},
  doi = {10.1016/j.envsoft.2010.12.005},
  url = {https://www.sciencedirect.com/science/article/pii/S1364815210003257},
  urldate = {2022-04-14},
  abstract = {Studies of animal movement are rapidly increasing as tracking technologies make it possible to collect more data of a larger variety of species. Comparisons of animal movement across sites, times, or species are key to asking questions about animal adaptation, responses to climate and land-use change. Thus, great gains can be made by sharing and exchanging animal tracking data. Here we present an animal movement data model that we use within the Movebank web application to describe tracked animals. The model facilitates data comparisons across a broad range of taxa, study designs, and technologies, and is based on the scientific questions that could be addressed with the data.},
  langid = {english},
  keywords = {Animal movement,Argos,Data model,GPS,Tracking,VHF Telemetry},
  file = {C\:\\Users\\David\\Zotero\\storage\\X6YQVE9L\\S1364815210003257.html}
}

@article{krishna,
  title = {Novel {{Approach}} to {{Museums Development}} \& {{Emergence}} of {{Text Mining}}},
  author = {Krishna, B V Rama and Sushma, B},
  volume = {2},
  number = {2},
  pages = {8},
  langid = {english},
  file = {C\:\\Users\\David\\Zotero\\storage\\JMWMDZG3\\Krishna and Sushma - Novel Approach to Museums Development & Emergence .pdf}
}

@article{krishtalka,
  title = {Accelerating the Discovery of Biocollections Data},
  author = {Krishtalka, Leonard and Dalcin, Eduardo and Ellis, Shari and Ganglo, Jean Cossi and Hosoya, Tsuyoshi and Nakae, Masanori and Owens, Ian and Paul, Deborah and Pignal, Marc and Thiers, Barbara},
  pages = {42},
  langid = {english},
  file = {C\:\\Users\\David\\Zotero\\storage\\DZLYUWPN\\Krishtalka et al. - Accelerating the discovery of biocollections data.pdf}
}

@article{krishtalka2000,
  title = {Can {{Natural History Museums Capture}} the {{Future}}?},
  author = {Krishtalka, Leonard and Humphrey, Philip S.},
  date = {2000-07-01},
  journaltitle = {BioScience},
  shortjournal = {BioScience},
  volume = {50},
  number = {7},
  pages = {611--617},
  issn = {0006-3568},
  doi = {10.1641/0006-3568(2000)050[0611:CNHMCT]2.0.CO;2},
  url = {https://doi.org/10.1641/0006-3568(2000)050[0611:CNHMCT]2.0.CO;2},
  urldate = {2022-04-01},
  file = {C\:\\Users\\David\\Zotero\\storage\\6JEMC4QD\\354777.html}
}

@book{lindsay2010,
  title = {Irresponsible Government: The Development of Political Attitudes and Alignments in the {{New South Wales Legislative Council}} 1843-1855},
  shorttitle = {Irresponsible Government},
  author = {Lindsay, Neville},
  date = {2010},
  publisher = {{Historia Productions}},
  location = {{Kenmore, Qld.}},
  isbn = {978-0-9808415-9-6},
  langid = {english},
  annotation = {OCLC: 659746914},
  file = {C\:\\Users\\David\\Zotero\\storage\\4388PPZR\\Neubig-KM-Whitten-WM-Abbott-JR-Elliott-S-Soltis-DE-Soltis-PS-2014-Variables-affecting-DNA-preservation-in-archival-DNA-specimens-In-Applequist-WL-Campbell-LM-eds-DNA-banking-in-the-21st-Century.pdf}
}

@article{lopez2020a,
  title = {Genomics of Natural History Collections for Understanding Evolution in the Wild},
  author = {Lopez, Lua and Turner, Kathryn G. and Bellis, Emily S. and Lasky, Jesse R.},
  date = {2020},
  journaltitle = {Molecular Ecology Resources},
  volume = {20},
  number = {5},
  pages = {1153--1160},
  issn = {1755-0998},
  doi = {10.1111/1755-0998.13245},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/1755-0998.13245},
  urldate = {2022-02-03},
  abstract = {A long-standing question in biology is how organisms change through time and space in response to their environment. This knowledge is of particular relevance to predicting how organisms might respond to future environmental changes caused by human-induced global change. Usually researchers make inferences about past events based on an understanding of current static genetic patterns, but these are limited in their capacity to inform on underlying past processes. Natural history collections (NHCs) represent a unique and critical source of information to provide temporally deep and spatially broad time-series of samples. By using NHC samples, researchers can directly observe genetic changes over time and space and link those changes with specific ecological/evolutionary events. Until recently, such genetic studies were hindered by the intrinsic challenges of NHC samples (i.e. low yield of highly fragmented DNA). However, recent methodological and technological developments have revolutionized the possibilities in the novel field of NHC genomics. In this Special Feature, we compile a range of studies spanning from methodological aspects to particular case studies which demonstrate the enormous potential of NHC samples for accessing large genomic data sets from the past to advance our knowledge on how populations and species respond to global change at multiple spatial–temporal scales. We also highlight possible limitations, recommendations and a few opportunities for future researchers aiming to study NHC genomics.},
  langid = {english},
  keywords = {aDNA,environmental change,evolution,natural history collections},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/1755-0998.13245}
}

@article{loturco2019,
  title = {{{DATA MODELING FOR MUSEUM COLLECTIONS}}},
  author = {Lo Turco, M. and Calvano, M. and Giovannini, E. C.},
  date = {2019-01-31},
  journaltitle = {The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
  shortjournal = {Int. Arch. Photogramm. Remote Sens. Spatial Inf. Sci.},
  volume = {XLII-2/W9},
  pages = {433--440},
  issn = {2194-9034},
  doi = {10.5194/isprs-archives-XLII-2-W9-433-2019},
  url = {https://www.int-arch-photogramm-remote-sens-spatial-inf-sci.net/XLII-2-W9/433/2019/},
  urldate = {2022-05-10},
  abstract = {The relationship between cultural heritage, digital technologies and visual models involves an increasingly wide area of research, oriented towards the renewal of archives and museums for the preservation and promotion of culture. Recent research activities are the result of the progressive strengthening of digital technologies and the needs of a new generation of "digital" users, which requires museums to update their means of communication using Semantic Web languages and technologies shaped by a social conceptualization of a graph-based representation of information.},
  langid = {english},
  file = {C\:\\Users\\David\\Zotero\\storage\\M625EBVA\\Lo Turco et al. - 2019 - DATA MODELING FOR MUSEUM COLLECTIONS.pdf}
}

@book{lovelace2019,
  title = {Geocomputation with {{R}}},
  author = {Lovelace, Robin and Nowosad, Jakub and Muenchow, Jannes},
  date = {2019-03-27},
  publisher = {{Chapman and Hall/CRC}},
  location = {{New York}},
  doi = {10.1201/9780203730058},
  abstract = {Geocomputation with R is for people who want to analyze, visualize and model geographic data with open source software. It is based on R, a statistical programming language that has powerful data processing, visualization, and geospatial capabilities. The book equips you with the knowledge and skills to tackle a wide range of issues manifested in geographic data, including those with scientific, societal, and environmental implications. This book will interest people from many backgrounds, especially Geographic Information Systems (GIS) users interested in applying their domain-specific knowledge in a powerful open source language for data science, and R users interested in extending their skills to handle spatial data. The book is divided into three parts: (I) Foundations, aimed at getting you up-to-speed with geographic data in R, (II) extensions, which covers advanced techniques, and (III) applications to real-world problems. The chapters cover progressively more advanced topics, with early chapters providing strong foundations on which the later chapters build. Part I describes the nature of spatial datasets in R and methods for manipulating them. It also covers geographic data import/export and transforming coordinate reference systems. Part II represents methods that build on these foundations. It covers advanced map making (including web mapping), "bridges" to GIS, sharing reproducible code, and how to do cross-validation in the presence of spatial autocorrelation. Part III applies the knowledge gained to tackle real-world problems, including representing and modeling transport systems, finding optimal locations for stores or services, and ecological modeling. Exercises at the end of each chapter give you the skills needed to tackle a range of geospatial problems. Solutions for each chapter and supplementary materials providing extended examples are available at https://geocompr.github.io/geocompkg/articles/.},
  isbn = {978-0-203-73005-8},
  pagetotal = {353}
}

@article{michel2018,
  title = {Integration of {{Web APIs}} and {{Linked Data Using SPARQL Micro-Services}}—{{Application}} to {{Biodiversity Use Cases}}},
  author = {Michel, Franck and Faron Zucker, Catherine and Gargominy, Olivier and Gandon, Fabien},
  date = {2018-12},
  journaltitle = {Information},
  volume = {9},
  number = {12},
  pages = {310},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {2078-2489},
  doi = {10.3390/info9120310},
  url = {https://www.mdpi.com/2078-2489/9/12/310},
  urldate = {2022-04-15},
  abstract = {In recent years, Web APIs have become a de facto standard for exchanging machine-readable data on the Web. Despite this success, however, they often fail in making resource descriptions interoperable due to the fact that they rely on proprietary vocabularies that lack formal semantics. The Linked Data principles similarly seek the massive publication of data on the Web, yet with the specific goal of ensuring semantic interoperability. Given their complementary goals, it is commonly admitted that cross-fertilization could stem from the automatic combination of Linked Data and Web APIs. Towards this goal, in this paper we leverage the micro-service architectural principles to define a SPARQL Micro-Service architecture, aimed at querying Web APIs using SPARQL. A SPARQL micro-service is a lightweight SPARQL endpoint that provides access to a small, resource-centric, virtual graph. In this context, we argue that full SPARQL Query expressiveness can be supported efficiently without jeopardizing servers availability. Furthermore, we demonstrate how this architecture can be used to dynamically assign dereferenceable URIs to Web API resources that do not have URIs beforehand, thus literally “bringing” Web APIs into the Web of Data. We believe that the emergence of an ecosystem of SPARQL micro-services published by independent providers would enable Linked Data-based applications to easily glean pieces of data from a wealth of distributed, scalable, and reliable services. We describe a working prototype implementation and we finally illustrate the use of SPARQL micro-services in the context of two real-life use cases related to the biodiversity domain, developed in collaboration with the French National Museum of Natural History.},
  issue = {12},
  langid = {english},
  keywords = {biodiversity,data integration,linked data,micro-service,REST,SPARQL,Web API},
  file = {C\:\\Users\\David\\Zotero\\storage\\J6C7G92F\\htm.html}
}

@software{michonneau2017,
  title = {Ridigbio: {{An}} Interface to {{iDigBio}}'s Search {{API}} That Allows Downloading Specimen Records.},
  author = {Michonneau, F and Collins, M and Chamberlain, S},
  date = {2017},
  origdate = {2014-11-06T16:17:21Z},
  url = {https://github.com/iDigBio/ridigbio},
  urldate = {2022-05-11},
  abstract = {ridigbio -- an R interface to iDigBio's API (see http://www.idigbio.org/)},
  organization = {{iDigBio}},
  version = {R package version 0.3.5}
}

@article{mitschick2013,
  title = {Livia {{Predoiu}}, {{University}} of {{Oxford}}, {{UK}}},
  author = {Mitschick, Annett and Nürnberger, Andreas and Risse, Thomas and Ross, Seamus},
  date = {2013},
  pages = {120},
  langid = {english},
  file = {C\:\\Users\\David\\Zotero\\storage\\C942W998\\Mitschick et al. - 2013 - Livia Predoiu, University of Oxford, UK.pdf}
}

@article{moritz2011,
  title = {Towards Mainstreaming of Biodiversity Data Publishing: Recommendations of the {{GBIF Data Publishing Framework Task Group}}},
  shorttitle = {Towards Mainstreaming of Biodiversity Data Publishing},
  author = {Moritz, Tom and Krishnan, S. and Roberts, Dave and Ingwersen, Peter and Agosti, Donat and Penev, Lyubomir and Cockerill, Matthew and Chavan, Vishwas},
  date = {2011-12-15},
  journaltitle = {BMC Bioinformatics},
  shortjournal = {BMC Bioinformatics},
  volume = {12},
  number = {15},
  pages = {S1},
  issn = {1471-2105},
  doi = {10.1186/1471-2105-12-S15-S1},
  url = {https://doi.org/10.1186/1471-2105-12-S15-S1},
  urldate = {2022-04-01},
  abstract = {Data are the evidentiary basis for scientific hypotheses, analyses and publication, for policy formation and for decision-making. They are essential to the evaluation and testing of results by peer scientists both present and future. There is broad consensus in the scientific and conservation communities that data should be freely, openly available in a sustained, persistent and secure way, and thus standards for 'free' and 'open' access to data have become well developed in recent years. The question of effective access to data remains highly problematic.},
  keywords = {Biodiversity Data,Global Biodiversity Information Facility,Metadata Record,Resource Description Framework,Task Group},
  file = {C\:\\Users\\David\\Zotero\\storage\\CTSR73UB\\1471-2105-12-S15-S1.html}
}

@article{nakahama2021,
  title = {Museum Specimens: {{An}} Overlooked and Valuable Material for Conservation Genetics},
  shorttitle = {Museum Specimens},
  author = {Nakahama, Naoyuki},
  date = {2021},
  journaltitle = {Ecological Research},
  volume = {36},
  number = {1},
  pages = {13--23},
  issn = {1440-1703},
  doi = {10.1111/1440-1703.12181},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/1440-1703.12181},
  urldate = {2022-02-03},
  abstract = {Museum specimens include genetic information from when they were collected. This historical information, which is very difficult to ascertain from samples collected currently, could be a valuable material for use in conservation genetics. However, the genetic analysis of museum specimens is technically difficult because of DNA fragmentation and the deamination of cytosine to uracil. In recent years, various methods have been developed for the genetic analysis of museum specimens, such as data analysis techniques including next-generation sequencing. The development of approaches that extract historical genetic information from museum specimens is expected to provide a new perspective on conservation genetics. This review focuses on the availability of museum specimens as genetic resources for conservation genetics. Some case studies are introduced, and perspectives on the future utility of conservation genetic studies using museum specimens are discussed. Moreover, recommended genetic analysis methods and important points for the usage of museum specimens are presented. This review provides a strong case for increasing the usage of museum specimens in conservation genetics studies in the future.},
  langid = {english},
  keywords = {conservation genetics,genetic diversity,museum,next-generation sequencing,specimen DNA},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/1440-1703.12181},
  file = {C\:\\Users\\David\\Zotero\\storage\\SHSJT85L\\1440-1703.html}
}

@article{nisheva-pavlova,
  title = {Museum {{Collections}} and the {{Semantic Web}}},
  author = {Nisheva-Pavlova, Maria and Spyratos, Nicolas and Stanchev, Peter},
  pages = {7},
  abstract = {The paper discusses some current trends in the area of development and use of semantic portals for accessing heterogeneous museum collections on the Semantic Web. The presentation is focused on some issues concerning metadata standards for museums, museum collections ontologies and semantic search engines. A number of design considerations and recommendations are formulated.},
  langid = {english},
  file = {C\:\\Users\\David\\Zotero\\storage\\IASLDT65\\Nisheva-Pavlova et al. - Museum Collections and the Semantic Web.pdf}
}

@article{norman2020,
  title = {Taxadb: {{A}} High-Performance Local Taxonomic Database Interface},
  shorttitle = {Taxadb},
  author = {Norman, Kari E. A. and Chamberlain, Scott and Boettiger, Carl},
  date = {2020},
  journaltitle = {Methods in Ecology and Evolution},
  volume = {11},
  number = {9},
  pages = {1153--1159},
  issn = {2041-210X},
  doi = {10.1111/2041-210X.13440},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.13440},
  urldate = {2022-05-11},
  abstract = {A familiar and growing challenge in ecological and evolutionary research is that of establishing consistent taxonomy when combining data from separate sources. While this problem is already well understood and numerous naming authorities have been created to address the issue, most researchers lack a fast, consistent, and intuitive way to retrieve taxonomic names. We present taxadb R package which creates a local database, managed automatically from within R, to provide fast operations on millions of taxonomic names. taxadb provides access to established naming authorities to resolve synonyms, taxonomic identifiers, and hierarchical classification in a consistent and intuitive data format. taxadb makes operation on millions of taxonomic names fast and manageable.},
  langid = {english},
  keywords = {diversity < community ecology,software < bioinformatics,systematics < phylogenetics},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/2041-210X.13440},
  file = {C\:\\Users\\David\\Zotero\\storage\\H6R9LMFC\\2041-210X.html}
}

@article{owens2021,
  title = {{{occCite}}: {{Tools}} for Querying and Managing Large Biodiversity Occurrence Datasets},
  shorttitle = {{{occCite}}},
  author = {Owens, Hannah L. and Merow, Cory and Maitner, Brian S. and Kass, Jamie M. and Barve, Vijay and Guralnick, Robert P.},
  date = {2021},
  journaltitle = {Ecography},
  volume = {44},
  number = {8},
  pages = {1228--1235},
  issn = {1600-0587},
  doi = {10.1111/ecog.05618},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/ecog.05618},
  urldate = {2022-03-25},
  abstract = {The amount of observational and specimen-based biodiversity data available to researchers is increasing exponentially, yet the ability to manage and cite large, complex biodiversity datasets lags behind. This management and citation gap impedes reproducibility for data users and the ability for data publishers to track use and accumulate use citations, ultimately harming the longer-term sustainability of the still-emerging enterprise of research data-sharing. Here we present an R package, occCite (v. 0.4.7), to aid researchers in querying large species occurrence data aggregators (specifically, the Global Biodiversity Information Facility, GBIF, and the Botanical Information and Ecology Network, BIEN), and store metadata such as primary data providers, database accession dates, DOIs, and the taxonomic source used for search terms. occCite also includes tools to summarize and visualize query results and generate citation lists of all data providers and software packages used during the query process. We provide examples of a basic occurrence search and citation workflow as well as an advanced workflow using features for custom optimized searches, visualization, and summary procedures. occCite improves upon existing R packages by uniting data from powerful API-based query packages (rgbif and BIEN) into a unified object-based framework, while maintaining metadata vital to best-practice recommendations for documenting biodiversity analysis workflows. occCite aims to efficiently close the gap in the citation cycle between primary data providers and final research products, allowing researchers to meet dataset documentation standards without sacrificing time and resources to the demands of providing increasing levels of detail on their datasets.},
  langid = {english},
  keywords = {citations,database aggregation,metadata,presence-only data,R package},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/ecog.05618},
  file = {C\:\\Users\\David\\Zotero\\storage\\3SV83DCH\\ecog.html}
}

@article{pennington2019,
  title = {Connecting the Silos:~{{Implementations}} and Perceptions of Linked Data across {{European}} Libraries},
  shorttitle = {Connecting the Silos},
  author = {Pennington, Diane Rasmussen and link will open in a new window Link to external site, this and Cagnazzo, Laura},
  date = {2019},
  journaltitle = {Journal of Documentation},
  volume = {75},
  number = {3},
  pages = {643--666},
  publisher = {{Emerald Group Publishing Limited}},
  location = {{Bradford, United Kingdom}},
  issn = {00220418},
  doi = {http://dx.doi.org/10.1108/JD-07-2018-0117},
  url = {https://www.proquest.com/docview/2218810400/abstract/5894C8ED1E224BE4PQ/1},
  urldate = {2022-04-02},
  abstract = {Purpose The purpose of this paper is to determine how information professionals in Scotland and in European national libraries perceive linked data (LD) as well as if and how they are implementing it. The authors applied four data collection techniques: a literature review, semi-structured interviews (n=15), online resources analysis (n=26) and an online survey (n=113). They used constant comparative analysis to identify perceived benefits and challenges of LD implementation, reasons behind adoption or non-adoption of LD and the issues hindering its implementation in libraries. Some projects demonstrate LD’s potential to augment the visibility and discoverability of library data, alongside with overcoming linguistic barriers, and supporting interoperability. However, a strong need remains to demonstrate the Semantic Web’s potential within libraries. Participants identified lack of expertise and lack of resources/time/staff as implementation barriers. Several other issues remain unsolved, such as licensing constraints, as well as difficulties with obtaining management buy-in for LD initiatives, even where open data are government-mandated. Information professionals and vendors should collaborate to develop tools for implementation. Advocacy through disseminating and reviewing successful implementations can help to solve practical difficulties and to obtain management buy-in. This is the first known study to present a multinational, comprehensive picture of library LD implementations and associated librarians’ perceptions of LD.},
  langid = {english},
  pagetotal = {24},
  keywords = {Cultural heritage,Europe,Library data,Linked data,Linked open data,Metadata standards,National libraries,Scottish libraries,Semantic Web,W3C}
}

@article{peters2016,
  title = {The {{Paleobiology Database}} Application Programming Interface},
  author = {Peters, Shanan E. and McClennen, Michael},
  date = {2016-02},
  journaltitle = {Paleobiology},
  volume = {42},
  number = {1},
  pages = {1--7},
  publisher = {{Cambridge University Press}},
  issn = {0094-8373, 1938-5331},
  doi = {10.1017/pab.2015.39},
  url = {https://www.cambridge.org/core/journals/paleobiology/article/paleobiology-database-application-programming-interface/4D20F5CAFA1B0AC7033975418668D82B},
  urldate = {2022-04-02},
  abstract = {The Paleobiology Database (PBDB; https://paleobiodb.org) consists of geographically and temporally explicit, taxonomically identified fossil occurrence data. The taxonomy utilized by the PBDB is not static, but is instead dynamically generated using an algorithm applied to separately managed taxonomic authority and opinion data. The PBDB owes its existence to many individuals, some of whom have entered more than 1.26 million fossil occurrences and over 570,000 taxonomic opinions, and some of whom have developed and maintained supporting infrastructure and analysis tools. Here, we provide an overview of the data model currently used by the PBDB and then briefly describe how this model is exposed via an Application Programming Interface (API). Our objective is to outline how PBDB data can now be accessed within individual scientific workflows, used to develop independently managed educational and scientific applications, and accessed to forge dynamic, near real-time connections to other data resources.},
  langid = {english},
  file = {C\:\\Users\\David\\Zotero\\storage\\NPTG3TQ8\\4D20F5CAFA1B0AC7033975418668D82B.html}
}

@article{poelen2014,
  title = {Global Biotic Interactions: {{An}} Open Infrastructure to Share and Analyze Species-Interaction Datasets},
  shorttitle = {Global Biotic Interactions},
  author = {Poelen, Jorrit H. and Simons, James D. and Mungall, Chris J.},
  date = {2014-11-01},
  journaltitle = {Ecological Informatics},
  shortjournal = {Ecological Informatics},
  volume = {24},
  pages = {148--159},
  issn = {1574-9541},
  doi = {10.1016/j.ecoinf.2014.08.005},
  url = {https://www.sciencedirect.com/science/article/pii/S1574954114001125},
  urldate = {2022-05-11},
  abstract = {An intricate network of interactions between organisms and their environment form the ecosystems that sustain life on earth. With a detailed understanding of these interactions, ecologists and biologists can make better informed predictions about the ways different environmental factors will impact ecosystems. Despite the abundance of research data on biotic and abiotic interactions, no comprehensive and easily accessible data collection is available that spans taxonomic, geospatial, and temporal domains. Biotic-interaction datasets are effectively siloed, inhibiting cross-dataset comparisons. In order to pool resources and bring to light individual datasets, specialized research tools are needed to aggregate, normalize, and integrate existing datasets with standard taxonomies, ontologies, vocabularies, and structured data repositories. Global Biotic Interactions (GloBI) provides such tools by way of an open, community-driven infrastructure designed to lower the barrier for researchers to perform ecological systems analysis and modeling. GloBI provides a tool that (a) ingests, normalizes, and aggregates datasets, (b) integrates interoperable data with accepted ontologies (e.g., OBO Relations Ontology, Uberon, and Environment Ontology), vocabularies (e.g., Coastal and Marine Ecological Classification Standard), and taxonomies (e.g., Integrated Taxonomic Information System and National Center for Biotechnology Information Taxonomy Database), (c) makes data accessible through an application programming interface (API) and various data archives (Darwin Core, Turtle, and Neo4j), and (d) houses a data collection of about 700,000 species interactions across about 50,000 taxa, covering over 1100 references from 19 data sources. GloBI has taken an open-source and open-data approach in order to make integrated species-interaction data maximally accessible and to encourage users to provide feedback, contribute data, and improve data access methods. The GloBI collection of datasets is currently used in the Encyclopedia of Life (EOL) and Gulf of Mexico Species Interactions (GoMexSI).},
  langid = {english},
  keywords = {Data integration,Ontology,Species interactions,Taxonomy},
  file = {C\:\\Users\\David\\Zotero\\storage\\YXPLLN4E\\S1574954114001125.html}
}

@software{prudhommeaux2013,
  title = {{{SPARQL}} 1.1 {{Query Language}}},
  author = {prud' {hommeaux}, Eric and Seaborne, Andy},
  options = {useprefix=true},
  date = {2013},
  url = {https://www.w3.org/TR/rdf-sparql-query/},
  urldate = {2022-05-10},
  file = {C\:\\Users\\David\\Zotero\\storage\\QIM43CL7\\REC-sparql11-query-20130321.html}
}

@article{raxworthy2021,
  title = {Mining Museums for Historical {{DNA}}: Advances and Challenges in Museomics},
  shorttitle = {Mining Museums for Historical {{DNA}}},
  author = {Raxworthy, Christopher J. and Smith, Brian Tilston},
  date = {2021-11-01},
  journaltitle = {Trends in Ecology \& Evolution},
  shortjournal = {Trends in Ecology \& Evolution},
  volume = {36},
  number = {11},
  pages = {1049--1060},
  issn = {0169-5347},
  doi = {10.1016/j.tree.2021.07.009},
  url = {https://www.sciencedirect.com/science/article/pii/S0169534721002147},
  urldate = {2022-02-03},
  abstract = {Historical DNA (hDNA), obtained from museum and herbarium specimens, has yielded spectacular new insights into the history of organisms. This includes documenting historical genetic erosion and extinction, discovering species new to science, resolving evolutionary relationships, investigating epigenetic effects, and determining origins of infectious diseases. However, the development of best-practices in isolating, processing, and analyzing hDNA remain under-explored, due to the substantial diversity of specimen preparation types, tissue sources, archival ages, and collecting histories. Thus, for hDNA to reach its full potential, and justify the destructive sampling of the rarest specimens, more experimental work using time-series collections, and the development of improved methods to correct for data asymmetries and biases due to DNA degradation are required.},
  langid = {english},
  keywords = {ancient DNA,bioinformatics,collections,DNA degradation,historical DNA,museomics},
  file = {C\:\\Users\\David\\Zotero\\storage\\P4LPWP6J\\S0169534721002147.html}
}

@article{reichman2011,
  title = {Challenges and {{Opportunities}} of {{Open Data}} in {{Ecology}}},
  author = {Reichman, O. J. and Jones, Matthew B. and Schildhauer, Mark P.},
  date = {2011-02-11},
  journaltitle = {Science},
  volume = {331},
  number = {6018},
  pages = {703--705},
  publisher = {{American Association for the Advancement of Science}},
  doi = {10.1126/science.1197962},
  url = {https://www.science.org/doi/full/10.1126/science.1197962},
  urldate = {2022-05-11}
}

@article{robertson2014,
  title = {The {{GBIF Integrated Publishing Toolkit}}: {{Facilitating}} the {{Efficient Publishing}} of {{Biodiversity Data}} on the {{Internet}}},
  shorttitle = {The {{GBIF Integrated Publishing Toolkit}}},
  author = {Robertson, Tim and Döring, Markus and Guralnick, Robert and Bloom, David and Wieczorek, John and Braak, Kyle and Otegui, Javier and Russell, Laura and Desmet, Peter},
  date = {2014-08-06},
  journaltitle = {PLOS ONE},
  shortjournal = {PLOS ONE},
  volume = {9},
  number = {8},
  pages = {e102623},
  publisher = {{Public Library of Science}},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0102623},
  url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0102623},
  urldate = {2022-03-25},
  abstract = {The planet is experiencing an ongoing global biodiversity crisis. Measuring the magnitude and rate of change more effectively requires access to organized, easily discoverable, and digitally-formatted biodiversity data, both legacy and new, from across the globe. Assembling this coherent digital representation of biodiversity requires the integration of data that have historically been analog, dispersed, and heterogeneous. The Integrated Publishing Toolkit (IPT) is a software package developed to support biodiversity dataset publication in a common format. The IPT’s two primary functions are to 1) encode existing species occurrence datasets and checklists, such as records from natural history collections or observations, in the Darwin Core standard to enhance interoperability of data, and 2) publish and archive data and metadata for broad use in a Darwin Core Archive, a set of files following a standard format. Here we discuss the key need for the IPT, how it has developed in response to community input, and how it continues to evolve to streamline and enhance the interoperability, discoverability, and mobilization of new data types beyond basic Darwin Core records. We close with a discussion how IPT has impacted the biodiversity research community, how it enhances data publishing in more traditional journal venues, along with new features implemented in the latest version of the IPT, and future plans for more enhancements.},
  langid = {english},
  keywords = {Archives,Biodiversity,Computer networks,Controlled vocabularies,Metadata,Software tools,United States,Vertebrates},
  file = {C\:\\Users\\David\\Zotero\\storage\\CBN2KC28\\article.html}
}

@article{rowe2011,
  title = {Museum Genomics: Low-Cost and High-Accuracy Genetic Data from Historical Specimens},
  shorttitle = {Museum Genomics},
  author = {Rowe, Kevin C. and Singhal, Sonal and Macmanes, Matthew D. and Ayroles, Julien F. and Morelli, Toni Lyn and Rubidge, Emily M. and Bi, Ke and Moritz, Craig C.},
  date = {2011},
  journaltitle = {Molecular Ecology Resources},
  volume = {11},
  number = {6},
  pages = {1082--1092},
  issn = {1755-0998},
  doi = {10.1111/j.1755-0998.2011.03052.x},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1755-0998.2011.03052.x},
  urldate = {2022-02-03},
  abstract = {Natural history collections are unparalleled repositories of geographical and temporal variation in faunal conditions. Molecular studies offer an opportunity to uncover much of this variation; however, genetic studies of historical museum specimens typically rely on extracting highly degraded and chemically modified DNA samples from skins, skulls or other dried samples. Despite this limitation, obtaining short fragments of DNA sequences using traditional PCR amplification of DNA has been the primary method for genetic study of historical specimens. Few laboratories have succeeded in obtaining genome-scale sequences from historical specimens and then only with considerable effort and cost. Here, we describe a low-cost approach using high-throughput next-generation sequencing to obtain reliable genome-scale sequence data from a traditionally preserved mammal skin and skull using a simple extraction protocol. We show that single-nucleotide polymorphisms (SNPs) from the genome sequences obtained independently from the skin and from the skull are highly repeatable compared to a reference genome.},
  langid = {english},
  keywords = {historical DNA,natural history collections,next-generation sequencing,Rattus},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1755-0998.2011.03052.x}
}

@article{saran2022,
  title = {A Comprehensive Review on Biodiversity Information Portals},
  author = {Saran, Sameer and Chaudhary, Sumit Kumar and Singh, Priyanka and Tiwari, Amrapali and Kumar, Vishal},
  date = {2022-04-28},
  journaltitle = {Biodiversity and Conservation},
  shortjournal = {Biodivers Conserv},
  issn = {1572-9710},
  doi = {10.1007/s10531-022-02420-x},
  url = {https://doi.org/10.1007/s10531-022-02420-x},
  urldate = {2022-05-11},
  abstract = {Biodiversity information and precise knowledge are critical for its conservation and management for sustainable development. With the advancement of information technology, various efforts have been made by the scientific and internet community to digitize the biodiversity information and put it on an open-source platform equipped with structured information, compiled knowledge, mapping, and spatial analysis tools. These portals assist researchers and conservation managers in a variety of ways, including providing open access bio-resource-related data and analysis tools, which has accelerated biodiversity and conservation research and management practices in recent years. The dissemination of knowledge about various aspect of these portals will expedite the current scenario. This paper is intended to highlight the various aspects of these portals. In this paper, globally recognized portals with rich biodiversity information, global coverage, and powerful spatial analysis tools are reviewed to characterize their vocabulary differences, strengths, and limitations. In addition to the global database, some country-specific initiatives that use biodiversity data in a geospatial context are included. It is observed that many portals have been solely developed for the purpose of creating an open access digital database of bio-resources, with the geographical aspect being ignored. Some of the global and regional initiatives such as Atlas of Living Australia (ALA), Global Biodiversity Information Facility (GBIF), etc. have attempted to fill this void by developing a variety of tools and integrating biodiversity data with geographic locations and other location-based parameters. Despite significant efforts, some issues remain unaddressed, viz., digitization of georeferenced information from natural history from across the world, the inclusion of more advanced web-GIS based tools for spatial analysis, development of agreed data standard, and so on, which could be the primary set of actions for future portals. The effort to address these issues is underway, and we anticipate that these will be resolved in the near future.},
  langid = {english},
  keywords = {Biodiversity conservation,Biodiversity information portals,Citizen science,Spatial data analytics,Sustainable development goal (SDG)}
}

@article{schuh2012,
  title = {Integrating Specimen Databases and Revisionary~Systematics},
  author = {Schuh, Randall T.},
  date = {2012-07-20},
  journaltitle = {ZooKeys},
  shortjournal = {Zookeys},
  number = {209},
  eprint = {22859892},
  eprinttype = {pmid},
  pages = {255--267},
  issn = {1313-2989},
  doi = {10.3897/zookeys.209.3288},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3406480/},
  urldate = {2022-03-25},
  abstract = {Arguments are presented for the merit of integrating specimen databases into the practice of revisionary systematics. Work flows, data connections, data outputs, and data standardization are enumerated as critical aspects of such integration. Background information is provided on the use of “barcodes” as unique specimen identifiers and on methods for efficient data capture. Examples are provided on how to achieve efficient workflows and data standardization, as well as data outputs and data integration.},
  pmcid = {PMC3406480}
}

@article{scott2019,
  title = {The {{Natural History Museum Data Portal}}},
  author = {Scott, Ben and Baker, Ed and Woodburn, Matt and Vincent, Sarah and Hardy, Helen and Smith, Vincent S},
  date = {2019-01-01},
  journaltitle = {Database},
  shortjournal = {Database},
  volume = {2019},
  pages = {baz038},
  issn = {1758-0463},
  doi = {10.1093/database/baz038},
  url = {https://doi.org/10.1093/database/baz038},
  urldate = {2022-04-01},
  abstract = {The Natural History Museum, London (NHM), generates and holds some of the largest global data sets relating to the biological and geological diversity of the natural world. A majority of these data were, until 2015, not widely accessible, and, even when published, were typically hard to find, poorly documented and in formats that impede discovery and integration. To better serve the bespoke needs of user communities outside and within the NHM, a dedicated data portal was developed to surface these data sets and provide a sustainable platform to encourage their citation and reuse. This paper describes the technical development of the data portal, from its inception to beta launch in December 2015, its first 2~years of operation, and future plans for the project. It outlines the development principles adopted for this prototypical project, which subsequently informed new digital project management methodologies at the NHM. The process of developing the data portal acted as a driver to implement policies necessary to encourage a culture of data sharing at the NHM.},
  file = {C\:\\Users\\David\\Zotero\\storage\\NX7ETNR8\\5432299.html}
}

@article{skevakis2014,
  title = {Metadata Management, Interoperability and {{Linked Data}} Publishing Support for {{Natural History Museums}}},
  author = {Skevakis, Giannis and Makris, Konstantinos and Kalokyri, Varvara and Arapi, Polyxeni and Christodoulakis, Stavros},
  date = {2014-08-01},
  journaltitle = {International Journal on Digital Libraries},
  shortjournal = {Int J Digit Libr},
  volume = {14},
  number = {3},
  pages = {127--140},
  issn = {1432-1300},
  doi = {10.1007/s00799-014-0114-2},
  url = {https://doi.org/10.1007/s00799-014-0114-2},
  urldate = {2022-04-01},
  abstract = {Natural history museums (NHMs) form a rich source of knowledge about Earth’s biodiversity and natural history. However, an impressive abundance of high-quality scientific content available in NHMs around Europe remains largely unexploited due to a number of barriers, such as the lack of interconnection and interoperability between the management systems used by museums, the lack of centralized access through a European point of reference such as Europeana and the inadequacy of the current metadata and content organization. The Natural Europe project offers a coordinated solution at European level that aims to overcome those barriers. In this article, we present the architecture, deployment and evaluation of the Natural Europe infrastructure allowing the curators to publish, semantically describe and manage the museums’ cultural heritage objects, as well as disseminate them to Europeana.eu and BioCASE/GBIF. Additionally, we discuss the methodology followed for the transition of the infrastructure to the Semantic Web and the publishing of NHMs’ cultural heritage metadata as Linked Data, supporting the Europeana Data Model.},
  langid = {english}
}

@article{stork2019,
  title = {Semantic Annotation of Natural History Collections},
  author = {Stork, Lise and Weber, Andreas and Gassó Miracle, Eulàlia and Verbeek, Fons and Plaat, Aske and van den Herik, Jaap and Wolstencroft, Katherine},
  options = {useprefix=true},
  date = {2019-12},
  journaltitle = {Journal of Web Semantics},
  shortjournal = {Journal of Web Semantics},
  volume = {59},
  pages = {100462},
  issn = {15708268},
  doi = {10.1016/j.websem.2018.06.002},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1570826818300283},
  urldate = {2022-04-02},
  abstract = {Large collections of historical biodiversity expeditions are housed in natural history museums throughout the world. Potentially they can serve as rich sources of data for cultural historical and biodiversity research. However, they exist as only partially catalogued specimen repositories and images of unstructured, non-standardised, hand-written text and drawings. Although many archival collections have been digitised, disclosing their content is challenging. They refer to historical place names and outdated taxonomic classifications and are written in multiple languages. Efforts to transcribe the hand-written text can make the content accessible, but semantically describing and interlinking the content would further facilitate research. We propose a semantic model that serves to structure the named entities in natural history archival collections. In addition, we present an approach for the semantic annotation of these collections whilst documenting their provenance. This approach serves as an initial step for an adaptive learning approach for semi-automated extraction of named entities from natural history archival collections. The applicability of the semantic model and the annotation approach is demonstrated using image scans from a collection of 8,000 field book pages gathered by the Committee for Natural History of the Netherlands Indies between 1820 and 1850, and evaluated together with domain experts from the field of natural and cultural history.},
  langid = {english},
  file = {C\:\\Users\\David\\Zotero\\storage\\CCBW5X2K\\Stork et al. - 2019 - Semantic annotation of natural history collections.pdf}
}

@article{thomer2018,
  title = {Supporting the Long-Term Curation and Migration of Natural History Museum Collections Databases},
  author = {Thomer, Andrea K. and Weber, Nicholas M. and Twidale, Michael B.},
  date = {2018},
  journaltitle = {Proceedings of the Association for Information Science and Technology},
  volume = {55},
  number = {1},
  pages = {504--513},
  issn = {2373-9231},
  doi = {10.1002/pra2.2018.14505501055},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/pra2.2018.14505501055},
  urldate = {2022-04-01},
  abstract = {Migration of data collections from one platform to another is an important component of data curation – yet, there is surprisingly little guidance for information professionals faced with this task. Data migration may be particularly challenging when these data collections are housed in relational databases, due to the complex ways that data, data schemas, and relational database management software become intertwined over time. Here we present results from a study of the maintenance, evolution and migration of research databases housed in Natural History Museums. We find that database migration is an on-going – rather than occasional – process for many Collection managers, and that they creatively appropriate and innovate on many existing technologies in their migration work. This paper contributes descriptions of a preliminary set of common adaptations and “migration patterns” in the practices of database curators. It also outlines the strategies they use when facing collection-level data migration and describes the limitations of existing tools in supporting LAM and “small science” research database migration. We conclude by outlining future research directions for the maintenance and migration of collections and complex digital objects.},
  langid = {english},
  keywords = {Data curation,database migration,museum informatics,natural history museums},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/pra2.2018.14505501055},
  file = {C\:\\Users\\David\\Zotero\\storage\\5B43NSI2\\pra2.2018.html}
}

@article{tin2014,
  title = {Sequencing {{Degraded DNA}} from {{Non-Destructively Sampled Museum Specimens}} for {{RAD-Tagging}} and {{Low-Coverage Shotgun Phylogenetics}}},
  author = {Tin, Mandy Man-Ying and Economo, Evan Philip and Mikheyev, Alexander Sergeyevich},
  date = {2014-05-14},
  journaltitle = {PLOS ONE},
  shortjournal = {PLOS ONE},
  volume = {9},
  number = {5},
  pages = {e96793},
  publisher = {{Public Library of Science}},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0096793},
  url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0096793},
  urldate = {2022-02-03},
  abstract = {Ancient and archival DNA samples are valuable resources for the study of diverse historical processes. In particular, museum specimens provide access to biotas distant in time and space, and can provide insights into ecological and evolutionary changes over time. However, archival specimens are difficult to handle; they are often fragile and irreplaceable, and typically contain only short segments of denatured DNA. Here we present a set of tools for processing such samples for state-of-the-art genetic analysis. First, we report a protocol for minimally destructive DNA extraction of insect museum specimens, which produced sequenceable DNA from all of the samples assayed. The 11 specimens analyzed had fragmented DNA, rarely exceeding 100 bp in length, and could not be amplified by conventional PCR targeting the mitochondrial cytochrome oxidase I gene. Our approach made these samples amenable to analysis with commonly used next-generation sequencing-based molecular analytic tools, including RAD-tagging and shotgun genome re-sequencing. First, we used museum ant specimens from three species, each with its own reference genome, for RAD-tag mapping. Were able to use the degraded DNA sequences, which were sequenced in full, to identify duplicate reads and filter them prior to base calling. Second, we re-sequenced six Hawaiian Drosophila species, with millions of years of divergence, but with only a single available reference genome. Despite a shallow coverage of 0.37±0.42 per base, we could recover a sufficient number of overlapping SNPs to fully resolve the species tree, which was consistent with earlier karyotypic studies, and previous molecular studies, at least in the regions of the tree that these studies could resolve. Although developed for use with degraded DNA, all of these techniques are readily applicable to more recent tissue, and are suitable for liquid handling automation.},
  langid = {english},
  keywords = {Ants,DNA extraction,Drosophila,Invertebrate genomics,Museum collections,Phylogenetics,Polymerase chain reaction,Shotgun sequencing},
  file = {C\:\\Users\\David\\Zotero\\storage\\MN8FXGL7\\article.html}
}

@article{v5a1s62013,
  title = {Taxize {{Source Code And Program Files}}},
  author = {V5A 1S6, Simon Fraser University, 8888 University Dr, Burnaby, BC, Canada, Scott A. Chamberlain Biology Department and Germany, University Koblenz-Landau, Fortstr 7, 76829 Landau, Eduard Szocs Institute For Environmental Sciences},
  date = {2013-09-11},
  publisher = {{Zenodo}},
  doi = {10.5281/ZENODO.7097},
  url = {https://zenodo.org/record/7097},
  urldate = {2022-04-01},
  abstract = {This is the code used in our article published in F1000Research entitled: taxize: taxonomic search and retrieval in R, without the accompanying text and description. This code should run in R without problems. Email scott@ropensci.org with any questions or problems.},
  langid = {english},
  file = {C\:\\Users\\David\\Zotero\\storage\\BMS7A86T\\V5A 1S6 and Germany - 2013 - Taxize Source Code And Program Files.pdf}
}

@incollection{van2011,
  title = {Natural {{Selection}}: {{Finding Specimens}} in a {{Natural History Collection}}},
  shorttitle = {Natural {{Selection}}},
  booktitle = {Changing {{Diversity}} in {{Changing Environment}}},
  author = {{van}, Marieke and van den Bosch, Antal and Hunt, Steve and van der Meij, Marian and Dekker, Rene and Lendvai, Piroska},
  editor = {Grillo, Oscar},
  options = {useprefix=true},
  date = {2011-11-14},
  publisher = {{InTech}},
  doi = {10.5772/25206},
  url = {http://www.intechopen.com/books/changing-diversity-in-changing-environment/natural-selection-finding-specimens-in-a-natural-history-collection},
  urldate = {2022-04-01},
  isbn = {978-953-307-796-3},
  langid = {english},
  file = {C\:\\Users\\David\\Zotero\\storage\\6PINZ4GA\\van et al. - 2011 - Natural Selection Finding Specimens in a Natural .pdf}
}

@article{varela2014,
  title = {{{rAvis}}: {{An R-Package}} for {{Downloading Information Stored}} in {{Proyecto AVIS}}, a {{Citizen Science Bird Project}}},
  shorttitle = {{{rAvis}}},
  author = {Varela, Sara and González-Hernández, Javier and Casabella, Eduardo and Barrientos, Rafael},
  date = {2014-03-13},
  journaltitle = {PLOS ONE},
  shortjournal = {PLOS ONE},
  volume = {9},
  number = {3},
  pages = {e91650},
  publisher = {{Public Library of Science}},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0091650},
  url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0091650},
  urldate = {2022-05-11},
  abstract = {Citizen science projects store an enormous amount of information about species distribution, diversity and characteristics. Researchers are now beginning to make use of this rich collection of data. However, access to these databases is not always straightforward. Apart from the largest and international projects, citizen science repositories often lack specific Application Programming Interfaces (APIs) to connect them to the scientific environments. Thus, it is necessary to develop simple routines to allow researchers to take advantage of the information collected by smaller citizen science projects, for instance, programming specific packages to connect them to popular scientific environments (like R). Here, we present rAvis, an R-package to connect R-users with Proyecto AVIS (http://proyectoavis.com), a Spanish citizen science project with more than 82,000 bird observation records. We develop several functions to explore the database, to plot the geographic distribution of the species occurrences, and to generate personal queries to the database about species occurrences (number of individuals, distribution, etc.) and birdwatcher observations (number of species recorded by each collaborator, UTMs visited, etc.). This new R-package will allow scientists to access this database and to exploit the information generated by Spanish birdwatchers over the last 40 years.},
  langid = {english},
  keywords = {Biogeography,Birds,Citizen science,Invasive species,Open source software,Ornithology,Scientists,Species diversity},
  file = {C\:\\Users\\David\\Zotero\\storage\\CIA8EZAP\\article.html}
}

@article{wandeler2007,
  title = {Back to the Future: Museum Specimens in Population Genetics},
  shorttitle = {Back to the Future},
  author = {Wandeler, Peter and Hoeck, Paquita E. A. and Keller, Lukas F.},
  date = {2007-12-01},
  journaltitle = {Trends in Ecology \& Evolution},
  shortjournal = {Trends in Ecology \& Evolution},
  volume = {22},
  number = {12},
  pages = {634--642},
  issn = {0169-5347},
  doi = {10.1016/j.tree.2007.08.017},
  url = {https://www.sciencedirect.com/science/article/pii/S0169534707002832},
  urldate = {2022-02-03},
  abstract = {Museums and other natural history collections (NHC) worldwide house millions of specimens. With the advent of molecular genetic approaches these collections have become the source of many fascinating population studies in conservation genetics that contrast historical with present-day genetic diversity. Recent developments in molecular genetics and genomics and the associated statistical tools have opened up the further possibility of studying evolutionary change directly. As we discuss here, we believe that NHC specimens provide a largely underutilized resource for such investigations. However, because DNA extracted from NHC samples is degraded, analyses of such samples are technically demanding and many potential pitfalls exist. Thus, we propose a set of guidelines that outline the steps necessary to begin genetic investigations using specimens from NHC.},
  langid = {english},
  file = {C\:\\Users\\David\\Zotero\\storage\\IVFW4KW4\\S0169534707002832.html}
}

@article{wieczorek2012,
  title = {Darwin {{Core}}: {{An Evolving Community-Developed Biodiversity Data Standard}}},
  shorttitle = {Darwin {{Core}}},
  author = {Wieczorek, John and Bloom, David and Guralnick, Robert and Blum, Stan and Döring, Markus and Giovanni, Renato and Robertson, Tim and Vieglais, David},
  date = {2012-01-06},
  journaltitle = {PLOS ONE},
  shortjournal = {PLOS ONE},
  volume = {7},
  number = {1},
  pages = {e29715},
  publisher = {{Public Library of Science}},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0029715},
  url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0029715},
  urldate = {2022-03-25},
  abstract = {Biodiversity data derive from myriad sources stored in various formats on many distinct hardware and software platforms. An essential step towards understanding global patterns of biodiversity is to provide a standardized view of these heterogeneous data sources to improve interoperability. Fundamental to this advance are definitions of common terms. This paper describes the evolution and development of Darwin Core, a data standard for publishing and integrating biodiversity information. We focus on the categories of terms that define the standard, differences between simple and relational Darwin Core, how the standard has been implemented, and the community processes that are essential for maintenance and growth of the standard. We present case-study extensions of the Darwin Core into new research communities, including metagenomics and genetic resources. We close by showing how Darwin Core records are integrated to create new knowledge products documenting species distributions and changes due to environmental perturbations.},
  langid = {english},
  keywords = {Archives,Biodiversity,Conservation science,Genomics,Metagenomics,Paleogenetics,Plant taxonomy,Taxonomy},
  file = {C\:\\Users\\David\\Zotero\\storage\\F2LW7P5J\\article.html}
}

@article{wieser2021,
  title = {A Local Platform for User-Friendly {{FAIR}} Data Management and Reproducible Analytics},
  author = {Wieser, Florian and Stryeck, Sarah and Lang, Konrad and Hahn, Christoph and Thallinger, Gerhard G. and Feichtinger, Julia and Hack, Philipp and Stepponat, Manfred and Merchant, Nirav and Lindstaedt, Stefanie and Oberdorfer, Gustav},
  date = {2021-11-20},
  journaltitle = {Journal of Biotechnology},
  shortjournal = {Journal of Biotechnology},
  volume = {341},
  pages = {43--50},
  issn = {0168-1656},
  doi = {10.1016/j.jbiotec.2021.08.004},
  url = {https://www.sciencedirect.com/science/article/pii/S0168165621002091},
  urldate = {2022-04-14},
  abstract = {Collaborative research is common practice in modern life sciences. For most projects several researchers from multiple universities collaborate on a specific topic. Frequently, these research projects produce a wealth of data that requires central and secure storage, which should also allow for easy sharing among project participants. Only under best circumstances, this comes with minimal technical overhead for the researchers. Moreover, the need for data to be analyzed in a reproducible way often poses a challenge for researchers without a data science background and thus represents an overly time-consuming process. Here, we report on the integration of CyVerse Austria (CAT), a new cyberinfrastructure for a local community of life science researchers, and provide two examples how it can be used to facilitate FAIR data management and reproducible analytics for teaching and research. In particular, we describe in detail how CAT can be used (i) as a teaching platform with a defined software environment and data management/sharing possibilities, and (ii) to build a data analysis pipeline using the Docker technology tailored to the needs and interests of the researcher.},
  langid = {english},
  keywords = {Bioinformatics,Cyberinfrastructure,CyVerse,FAIR,Research data management,Teaching},
  file = {C\:\\Users\\David\\Zotero\\storage\\5CNUJZM3\\S0168165621002091.html}
}

@article{wilkinson2016,
  title = {The {{FAIR Guiding Principles}} for Scientific Data Management and Stewardship},
  author = {Wilkinson, Mark D. and Dumontier, Michel and Aalbersberg, I. Jsbrand Jan and Appleton, Gabrielle and Axton, Myles and Baak, Arie and Blomberg, Niklas and Boiten, Jan-Willem and da Silva Santos, Luiz Bonino and Bourne, Philip E. and Bouwman, Jildau and Brookes, Anthony J. and Clark, Tim and Crosas, Mercè and Dillo, Ingrid and Dumon, Olivier and Edmunds, Scott and Evelo, Chris T. and Finkers, Richard and Gonzalez-Beltran, Alejandra and Gray, Alasdair J. G. and Groth, Paul and Goble, Carole and Grethe, Jeffrey S. and Heringa, Jaap and 't Hoen, Peter A. C. and Hooft, Rob and Kuhn, Tobias and Kok, Ruben and Kok, Joost and Lusher, Scott J. and Martone, Maryann E. and Mons, Albert and Packer, Abel L. and Persson, Bengt and Rocca-Serra, Philippe and Roos, Marco and van Schaik, Rene and Sansone, Susanna-Assunta and Schultes, Erik and Sengstag, Thierry and Slater, Ted and Strawn, George and Swertz, Morris A. and Thompson, Mark and van der Lei, Johan and van Mulligen, Erik and Velterop, Jan and Waagmeester, Andra and Wittenburg, Peter and Wolstencroft, Katherine and Zhao, Jun and Mons, Barend},
  options = {useprefix=true},
  date = {2016-03-15},
  journaltitle = {Scientific Data},
  shortjournal = {Sci Data},
  volume = {3},
  eprint = {26978244},
  eprinttype = {pmid},
  pages = {160018},
  issn = {2052-4463},
  doi = {10.1038/sdata.2016.18},
  abstract = {There is an urgent need to improve the infrastructure supporting the reuse of scholarly data. A diverse set of stakeholders-representing academia, industry, funding agencies, and scholarly publishers-have come together to design and jointly endorse a concise and measureable set of principles that we refer to as the FAIR Data Principles. The intent is that these may act as a guideline for those wishing to enhance the reusability of their data holdings. Distinct from peer initiatives that focus on the human scholar, the FAIR Principles put specific emphasis on enhancing the ability of machines to automatically find and use the data, in addition to supporting its reuse by individuals. This Comment is the first formal publication of the FAIR Principles, and includes the rationale behind them, and some exemplar implementations in the community.},
  langid = {english},
  pmcid = {PMC4792175},
  keywords = {Data Collection,Data Curation,Database Management Systems,Guidelines as Topic,Reproducibility of Results,Research Design}
}

@article{wilkinson2016a,
  title = {The {{FAIR Guiding Principles}} for Scientific Data Management and Stewardship},
  author = {Wilkinson, Mark D. and Dumontier, Michel and Aalbersberg, IJsbrand Jan and Appleton, Gabrielle and Axton, Myles and Baak, Arie and Blomberg, Niklas and Boiten, Jan-Willem and da Silva Santos, Luiz Bonino and Bourne, Philip E. and Bouwman, Jildau and Brookes, Anthony J. and Clark, Tim and Crosas, Mercè and Dillo, Ingrid and Dumon, Olivier and Edmunds, Scott and Evelo, Chris T. and Finkers, Richard and Gonzalez-Beltran, Alejandra and Gray, Alasdair J. G. and Groth, Paul and Goble, Carole and Grethe, Jeffrey S. and Heringa, Jaap and ’t Hoen, Peter A. C. and Hooft, Rob and Kuhn, Tobias and Kok, Ruben and Kok, Joost and Lusher, Scott J. and Martone, Maryann E. and Mons, Albert and Packer, Abel L. and Persson, Bengt and Rocca-Serra, Philippe and Roos, Marco and van Schaik, Rene and Sansone, Susanna-Assunta and Schultes, Erik and Sengstag, Thierry and Slater, Ted and Strawn, George and Swertz, Morris A. and Thompson, Mark and van der Lei, Johan and van Mulligen, Erik and Velterop, Jan and Waagmeester, Andra and Wittenburg, Peter and Wolstencroft, Katherine and Zhao, Jun and Mons, Barend},
  options = {useprefix=true},
  date = {2016-03-15},
  journaltitle = {Scientific Data},
  shortjournal = {Sci Data},
  volume = {3},
  number = {1},
  pages = {160018},
  publisher = {{Nature Publishing Group}},
  issn = {2052-4463},
  doi = {10.1038/sdata.2016.18},
  url = {https://www.nature.com/articles/sdata201618},
  urldate = {2022-05-10},
  abstract = {There is an urgent need to improve the infrastructure supporting the reuse of scholarly data. A diverse set of stakeholders—representing academia, industry, funding agencies, and scholarly publishers—have come together to design and jointly endorse a concise and measureable set of principles that we refer to as the FAIR Data Principles. The intent is that these may act as a guideline for those wishing to enhance the reusability of their data holdings. Distinct from peer initiatives that focus on the human scholar, the FAIR Principles put specific emphasis on enhancing the ability of machines to automatically find and use the data, in addition to supporting its reuse by individuals. This Comment is the first formal publication of the FAIR Principles, and includes the rationale behind them, and some exemplar implementations in the community.},
  issue = {1},
  langid = {english},
  keywords = {Publication characteristics,Research data},
  file = {C\:\\Users\\David\\Zotero\\storage\\T7LT75ZN\\sdata201618.html}
}

@article{yeates2016,
  title = {Museums Are Biobanks: Unlocking the Genetic Potential of the Three Billion Specimens in the World's Biological Collections},
  shorttitle = {Museums Are Biobanks},
  author = {Yeates, David K and Zwick, Andreas and Mikheyev, Alexander S},
  date = {2016-12-01},
  journaltitle = {Current Opinion in Insect Science},
  shortjournal = {Current Opinion in Insect Science},
  series = {Neuroscience * {{Special Section}} on {{Insect}} Phylogenetics},
  volume = {18},
  pages = {83--88},
  issn = {2214-5745},
  doi = {10.1016/j.cois.2016.09.009},
  url = {https://www.sciencedirect.com/science/article/pii/S2214574516301596},
  urldate = {2022-02-03},
  abstract = {Museums and herbaria represent vast repositories of biological material. Until recently, working with these collections has been difficult, due to the poor condition of historical DNA. However, recent advances in next-generation sequencing technology, and subsequent development of techniques for preparing and sequencing historical DNA, have recently made working with collection specimens an attractive option. Here we describe the unique technical challenges of working with collection specimens, and innovative molecular methods developed to tackle them. We also highlight possible applications of collection specimens, for taxonomy, ecology and evolution. The application of next-generation sequencing methods to museum and herbaria collections is still in its infancy. However, by giving researchers access to billions of specimens across time and space, it holds considerable promise for generating future discoveries across many fields.},
  langid = {english},
  file = {C\:\\Users\\David\\Zotero\\storage\\NU9BRG4E\\S2214574516301596.html}
}

@article{zimkus2014,
  title = {Best Practices for Genetic Resources Associated with Natural History Collections: {{Recommendations}} for Practical Implementation},
  shorttitle = {Best Practices for Genetic Resources Associated with Natural History Collections},
  author = {Zimkus, Breda M and Ford, Linda S},
  date = {2014-01-01},
  journaltitle = {Collection Forum},
  shortjournal = {Collection Forum},
  volume = {28},
  number = {1-2},
  pages = {77--112},
  issn = {0831-4985},
  doi = {10.14351/0831-0005-28.1.77},
  url = {https://doi.org/10.14351/0831-0005-28.1.77},
  urldate = {2022-04-01},
  abstract = {Researchers associated with natural history museums have made the collection of genetic resources a priority due to their importance in molecular studies, but often the long-term curation of these collections is difficult due to decentralized curation over multiple storage locations and lack of community best practice guidelines for their stewardship. Unlike traditional natural history specimens, the research utility of genetic samples increases with lower storage temperatures and fewer freeze–thaw events and, in addition, their use is consumptive. Collection managers must, therefore, maximize the research potential of each sample by carefully considering use on a case-by-case basis. This paper presents standardized guidelines accumulated for the management of genetic collections associated with natural history collections. These recommended practices are informed by general standards for biorepositories and augmented by information unique to natural history collections with the goal of providing a foundation for those curating genetic samples. Information pertains to all aspects of genetic sample curation and will assist those in making decisions regarding how to collect, store, track, process, and distribute genetic specimen samples. These guidelines also will allow users to make informed decisions regarding how to apply and improve the curation of their collection given their institution's goals and available resources.},
  file = {C\:\\Users\\David\\Zotero\\storage\\9J9SLQJI\\Best-practices-for-genetic-resources-associated.html}
}

@online{zotero-undefined,
  title = {Darwin {{Core}} - {{TDWG}}},
  url = {https://www.tdwg.org/standards/dwc/},
  urldate = {2022-04-02},
  file = {C\:\\Users\\David\\Zotero\\storage\\Z5RRMDFJ\\dwc.html}
}

@online{zotero-undefinedb,
  title = {Resource {{Description Framework}} ({{RDF}}) {{Model}} and {{Syntax Specification}}},
  url = {https://www.w3.org/TR/PR-rdf-syntax/},
  urldate = {2022-04-02},
  file = {C\:\\Users\\David\\Zotero\\storage\\HY4B9YSC\\PR-rdf-syntax.html}
}

@online{zotero-undefinedc,
  title = {Using an {{RDF Data Pipeline}} to {{Implement Cross-Collection Search}} | Museumsandtheweb.Com},
  url = {https://www.museumsandtheweb.com/mw2012/papers/using_an_rdf_data_pipeline_to_implement_cross_.html},
  urldate = {2022-04-02},
  file = {C\:\\Users\\David\\Zotero\\storage\\X6434ND3\\using_an_rdf_data_pipeline_to_implement_cross_.html}
}

@online{zotero-undefinede,
  title = {{{SPARQL Endpoint}} Interface to {{Python}} — {{SPARQLWrapper}} Documentation},
  url = {https://sparqlwrapper.readthedocs.io/en/latest/},
  urldate = {2022-05-11},
  file = {C\:\\Users\\David\\Zotero\\storage\\AZMDVP2R\\latest.html}
}

@preamble{ "\ifdefined\DeclarePrefChars\DeclarePrefChars{'’-}\else\fi " }

